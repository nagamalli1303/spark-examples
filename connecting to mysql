<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>com.spark.pkg</groupId>
	<artifactId>ScalaProject</artifactId>
	<version>0.0.1-SNAPSHOT</version>

	<dependencies>
		<dependency> <!-- Spark -->
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_2.10</artifactId>
			<version>1.5.1</version>
			<scope>provided</scope>
		</dependency>
		<dependency> <!-- Spark Streaming -->
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_2.10</artifactId>
			<version>1.5.1</version>
			<scope>provided</scope>
		</dependency>
		<dependency> <!-- Kafka -->
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka_2.10</artifactId>
			<version>0.9.0.0</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.kafka</groupId>
			<artifactId>kafka-clients</artifactId>
			<version>0.9.0.0</version>
		</dependency>
		<dependency> <!-- Command Line Parsing -->
			<groupId>commons-cli</groupId>
			<artifactId>commons-cli</artifactId>
			<version>1.2</version>
		</dependency>
		
		<dependency>
    		<groupId>mysql</groupId>
    		<artifactId>mysql-connector-java</artifactId>
    		<version>5.1.39</version>
		</dependency>

		<!-- <dependency> <groupId>org.apache.kafka</groupId> <artifactId>kafka_2.9.2</artifactId> 
			<version>0.8.1.1</version> <scope>compile</scope> <exclusions> <exclusion> 
			<artifactId>jmxri</artifactId> <groupId>com.sun.jmx</groupId> </exclusion> 
			<exclusion> <artifactId>jms</artifactId> <groupId>javax.jms</groupId> </exclusion> 
			<exclusion> <artifactId>jmxtools</artifactId> <groupId>com.sun.jdmk</groupId> 
			</exclusion> </exclusions> </dependency> -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka_2.10</artifactId>
			<version>1.5.1</version>
		</dependency>
		<dependency> <!-- Spark SQL -->
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_2.10</artifactId>
			<version>1.5.1</version>
			<scope>provided</scope>
		</dependency>
		<dependency> <!-- Spark HIVE -->
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_2.10</artifactId>
			<version>1.5.1</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-common</artifactId>
			<version>0.98.8-hadoop2</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-server</artifactId>
			<version>0.98.8-hadoop2</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-client</artifactId>
			<version>0.98.8-hadoop2</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-client</artifactId>
			<version>2.4.1</version>
		</dependency>
		<dependency>
			<groupId>org.apache.storm</groupId>
			<artifactId>storm-core</artifactId>
			<version>0.9.5</version>
		</dependency>
	</dependencies>
	<build>
		<plugins>
			<plugin>
				<artifactId>maven-assembly-plugin</artifactId>
				<version>2.4</version>
				<configuration>
					<descriptorRefs>
						<descriptorRef>jar-with-dependencies</descriptorRef>
					</descriptorRefs>
				</configuration>
				<executions>
					<execution>
						<id>make-assembly</id>
						<phase>package</phase>
						<goals>
							<goal>single</goal>
						</goals>
					</execution>
				</executions>
			</plugin>
		</plugins>
	</build>
</project>

package com.spark.pkg

import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.sql.SQLContext
import org.apache.spark.sql.DataFrame
import java.sql.DriverManager
import java.sql.Connection
import java.sql.ResultSet
import org.apache.spark.sql.functions._
import org.apache.spark.sql.Row
import scala.collection.mutable.ListBuffer
import scala.collection.mutable.MutableList

object SparkMysqlV{
  
//  case class Person(name: String, age: Int)
  
  def main(args: Array[String]) = {
    
    val conf = new SparkConf().setAppName("WordSQL").setMaster("local")
      
    val sc = new SparkContext(conf)

    val sqlContext = new org.apache.spark.sql.SQLContext(sc)
    import sqlContext.implicits._
    
//    val sqlContext = new org.apache.spark.sql.hive.HiveContext(sc)
//    import sqlContext.implicits._

//    val schemaName = "information_schema"
    val schemaName = "test"
    val conn_str = "jdbc:mysql://localhost:3306/" + schemaName
    val driver =  "com.mysql.jdbc.Driver"
    val usr = "root"
    val pwd = "root"
    val tbl = "columns"
    
//    val dataframe_mysql =  sqlContext.read.format("jdbc").option("url", conn_str).option("driver",driver).
//    option("dbtable", tbl).option("user", usr).option("password", pwd).load().where($"TABLE_SCHEMA" === "app")
    
//    val output = "/home/work/output/sparmysqloutput"
//    dataframe_mysql.rdd.saveAsTextFile(output)
    
    val appid = "app"
    val qry1 = """(select * from """ + schemaName + """.test_apps where app_id = """"+ appid + """") test"""
    
    val qry = """(	
    select 
    test_apps.app_id,
    test_apps.app_name,
    test_apps.contact,
    test_rules.rule_id,
    test_rules.rule_desc,
    test_rules.rule_type,
    test_rules.rule_message,
    test_rules.rule_actions,    
    test_master_table.object_id,
    test_master_table.object_type,
    test_master_table.schema_name,
    test_master_table.object_name,
    test_master_table.column_name,
    test_master_table.column_datatype,
    test_master_table.length,
    test_master_table.scale,
    test_master_table.precession,    
    test_master_table.cluster_id,
    test_master_table.rule_id as master_rule_id,
    test_master_table.active_flag as master_active_flag,
    test_master_table.operators,
    test_master_table.file_delim,
    test_master_table.columns_priority,
    test_rules_map.active_flag    
    from test.test_apps as test_apps,test.test_rules as test_rules,
         test.test_master_table as test_master_table,  
         test.test_rules_map as test_rules_map
    where test_apps.app_id = test_master_table.app_id and 
             test_rules.rule_id = test_rules_map.rule_id and 
             test_master_table.object_id = test_rules_map.object_id and 
             test_rules_map.rule_id = test_rules.rule_id 
             and test_apps.app_id = """" + appid + """" 
             order by test_master_table.object_name,test_rules.rule_id) test"""
    
    val test_qry = s"select test_apps.app_id, test_apps.app_name, test_apps.contact, " + 
     "test_rules.rule_id, test_rules.rule_desc, test_rules.rule_type, test_rules.rule_message, " + 
     "test_rules.rule_actions, " +
     "test_master_table.object_id, test_master_table.object_type, test_master_table.schema_name, " +
     "test_master_table.object_name, test_master_table.column_name, test_master_table.column_datatype, " +
     "test_master_table.length, test_master_table.scale, test_master_table.precession, " +
     "test_master_table.cluster_id, test_master_table.rule_id as master_rule_id, " +
     "test_master_table.active_flag as master_active_flag, test_master_table.operators, " +    
     "test_master_table.file_delim, test_master_table.columns_priority, " +
     "test_rules_map.active_flag " +    
     "from test.test_apps as test_apps,test.test_rules as test_rules," +
     "test.test_master_table as test_master_table, test.test_rules_map as test_rules_map " +
     "where test_apps.app_id = test_master_table.app_id and " + 
     "test_rules.rule_id = test_rules_map.rule_id and " +
     "test_master_table.object_id = test_rules_map.object_id and " + 
     "test_rules_map.rule_id = test_rules.rule_id " + 
     "and test_apps.app_id = " + "\"" + appid + "\" " + 
     "order by test_master_table.object_name,test_rules.rule_id"   

    var connection:Connection = null
    var tbl_name = ""
    var test_df : DataFrame = null
    var resultSet:ResultSet = null
    var test_table_df: DataFrame = null
    var test_table_rules_df: DataFrame = null
    
    
    var test_master_df : DataFrame = null
    test_master_df = sqlContext.read.format("jdbc").options(          
        			Map("url" ->  conn_str,
        					"driver" -> driver,
        					"user" -> usr,
        					"password" -> pwd,
        					"dbtable" -> qry
        					//    				"fetchSize" -> "10000"   
        					)).load()
        					
    test_master_df.show
    
    var test_table_list = test_master_df.select("object_type","object_name").distinct()
    .map(r => (r.getString(0), r.getString(1))).collect().toList
    
    test_table_list.foreach { x => {
      
      var object_type = x._1
      
      if (object_type.toLowerCase() == "table") {        
        var table_name = x._2
      
        import sqlContext.implicits._
        
        test_table_rules_df = test_master_df.where($"object_name" === table_name)
        
        var test_table_rules_list = test_table_rules_df.rdd.collect.toList
        println (test_table_rules_list.getClass)
        
        test_table_rules_df.show
        
        test_table_df = sqlContext.read.format("jdbc").options(          
        		Map("url" ->  conn_str,
            		"driver" -> driver,
          			"user" -> usr,
          			"password" -> pwd,
          			"dbtable" -> table_name
          			//    				"fetchSize" -> "10000"   
          			)).load()
        var result = List[(String)]()  			
        var object_result = List[(String)]()
        process_testRules(test_table_df,test_table_rules_list)
        object_result = result
        test_table_df.show()
        
        }else if(object_type.toLowerCase() == "file") {
          println("file handling logic")
          
        }else{
          println("specified object type not handling, please provide object type as table or file")
        } 
      }                    					       					
    }
    
    def process_testRules(test_table_df:DataFrame, test_table_rules_list:List[Row]): Unit = {
      println("in process testRules")
      test_table_df.show
      
      test_table_df.foreach { table_row => {        
        println("table_row:" + table_row)
          test_table_rules_list.foreach { rules_row => {
            
            println("rules_row:" + rules_row)
            
            var rule_id = rules_row.getInt(3).toString()
            var object_name = rules_row.getString(11)
            var column_name = rules_row.getString(12)
            println("in process test rules:" + rule_id + " object_name:" + object_name + " column_name:" + column_name)
            
            rule_id match {
              case "1" => numeric_data_check(rules_row,table_row)
//              case "2" => data_length_check(rules_row,table_row)
              case "3" => timestamp_format_check(rules_row,table_row)
              case "4" => date_format_check(rules_row,table_row)
              case "5" => 
                          columns_priority_check(rules_row,table_row)
              case _ => print("rule not matched")        
            }
            
            } 
          }    
          
        } 
      }
    }
         
    def numeric_data_check(rules_row:Row, table_row:Row): Unit = {
       println("numeric data check:")
//      column_values.show()
    }
    
    def data_length_check(rules_row:Row, table_row:Row): Unit = {
      var app_id = rules_row.toString() 
    	var app_name = rules_row.getString(1)
    	var contact = rules_row.getString(2)
    	var rule_id = rules_row.getInt(3)  
    	var rule_desc = rules_row.getString(4)
    	var rule_type = rules_row.getString(5)
    	var rule_message = rules_row.getString(6)
    	var rule_actions = rules_row.getString(7)    	
    	var object_id = rules_row.getInt(8)
    	var object_type = rules_row.getString(9)
    	var schema_name = rules_row.getString(10)
    	var object_name = rules_row.getString(11)
    	var column_name = rules_row.getString(12)
    	var column_datatype = rules_row.getString(13)
    	var length = rules_row.getInt(14)
    	var scale = rules_row.getInt(15)
    	var precession = rules_row.getInt(16)
    	var cluster_id = rules_row.getString(17)
    	var master_rule_id = rules_row.getInt(18)
    	var master_active_flag = rules_row.getInt(19)
    	var operators = rules_row.getString(20)
    	var file_delim = rules_row.getString(21)
    	var columns_priority = rules_row.getString(22)
    	var active_flag = rules_row.getInt(23)
    	
    	println(table_row.schema)
    	var fields = table_row.schema.fields
    	var field_name:String = ""
    	var field_name_m: String = "" 
      var field_dataType_m: String = ""
      var field_dataType = ""
      var idx = 0
      var pos = 0
      
//        var rule_process_fields : ListBuffer[(String,String)] = ListBuffer()
      var rule_process_fields  = List[(String, String)]()
      println("length:" + fields.length + " " + fields(0) + " " + fields(1) + " " + fields(6))
      fields.foreach { x => {        
        field_name = x.name 
        var data_type = x.dataType.toString()
        idx += 1
        field_dataType = ""
        
        data_type match {
            case "IntegerType" | "LongType" | "ShortType" => field_dataType = "Int"
            case "StringType" => field_dataType = "String"
            case "DoubleType" => field_dataType = "Decimal"
            case "DecimalType" => field_dataType = "Decimal"
            case "DateType" => field_dataType = "Date"
            case "FloatType" => field_dataType = "Float" 
            case "BooleanType" => field_dataType = "Boolean"
            case "TimestampType" => field_dataType = "Timestamp"
            case "ListType" => field_dataType = "List" 
        }
//          println(x.name + "  " + x.dataType)          
        if (field_name == column_name){
          rule_process_fields =  ((column_name,field_dataType)) :: rule_process_fields
          field_name_m = field_name 
          field_dataType_m = field_dataType
          pos = idx - 1
          println(field_name_m + " == " + column_name + " " + field_dataType_m + " " + pos)
        }
      }
    }
      println("rule_process_fields:" + rule_process_fields)           
    	var actions = rule_actions.split(",")
      
    	for(i <- 0 to actions.length-1){
    	  println("action:" + actions(i))
    	  
    	  if (field_name_m == column_name){
            if (field_dataType_m.toLowerCase() == "string" ){
              println(field_dataType_m.toLowerCase() + " == string" )
              
              if (actions(i).toLowerCase() == "null") {
                  println("null test column :" + table_row.getString(pos))
                if(table_row.getString(pos) == null && table_row.getString(pos).isEmpty()) {
                  println("column :" + table_row.getString(pos) + " is null")                
                }               
              }            
              else if (actions(i).toLowerCase() == "space") {
                println("space test column :" + table_row.getString(pos))
                if(table_row.getString(pos).trim().isEmpty()){
                  println("column :" + table_row.getString(pos) + " is spaces")
                } 
              }
              else if (actions(i).toLowerCase() == "length") {
                println("length test column :" + table_row.getString(pos))
                operators match {                  
                  case "<" => if(table_row.getString(pos).length() < length)
                                  println("length table_row.getString(pos).length() " + "<" + length)
                  case "<=" => if(table_row.getString(pos).length() <= length)
                                  println("length table_row.getString(pos).length() " + "<=" + length)
                  case "=" => if(table_row.getString(pos).length() == length)
                                  println("length table_row.getString(pos).length() " + "==" + length)
                  case ">" => if(table_row.getString(pos).length() > length)
                                  println("length table_row.getString(pos).length() " + ">" + length)
                  case ">=" => if(table_row.getString(pos).length() >= length)
                                  println("length table_row.getString(pos).length() " + ">=" + length)                      
                  case _    =>  println("invlaid operator for length")                    
                }
              }  
            }
    	  }  
      }
      
      println("data lenth check:")
    }
    
    def timestamp_format_check(rules_row:Row, table_row:Row): Unit = {
      	
      println("timestamp format check")
    }
    
    def date_format_check(rules_row:Row, table_row:Row): Unit = {
          	
      println("date format check")
    }
    
    def columns_priority_check(rules_row:Row, table_row:Row): Unit = {
      var app_id = rules_row.toString() 
    	var app_name = rules_row.getString(1)
    	var contact = rules_row.getString(2)
    	var rule_id = rules_row.getInt(3)  
    	var rule_desc = rules_row.getString(4)
    	var rule_type = rules_row.getString(5)
    	var rule_message = rules_row.getString(6)
    	var rule_actions = rules_row.getString(7)    	
    	var object_id = rules_row.getInt(8)
    	var object_type = rules_row.getString(9)
    	var schema_name = rules_row.getString(10)
    	var object_name = rules_row.getString(11)
    	var column_name = rules_row.getString(12)
    	var column_datatype = rules_row.getString(13)
    	var length = rules_row.getInt(14)
    	var scale = rules_row.getInt(15)
    	var precession = rules_row.getInt(16)
    	var cluster_id = rules_row.getString(17)
    	var master_rule_id = rules_row.getInt(18)
    	var master_active_flag = rules_row.getInt(19)
    	var operators = rules_row.getString(20)
    	var file_delim = rules_row.getString(21)
    	var columns_priority = rules_row.getString(22)
    	var active_flag = rules_row.getInt(23)
    		
    	println(table_row.schema)
    	var fields = table_row.schema.fields
    	var field_name:String = ""
    	var field_name_m: String = "" 
      var field_dataType_m: String = ""
      var field_pos_m: Int = 0 
      var field_dataType = ""      
      var idx = 0
      var pos = 0
      
//        var rule_process_fields : ListBuffer[(String,String)] = ListBuffer()
      var rule_process_fields  = List[(String,String,Int)]()
//      println("length:" + fields.length + " " + fields(0) + " " + fields(1) + " " + fields(6))
      
      var columns = columns_priority.split(",")
      
      fields.foreach { x => {
        
        field_name = x.name 
        var data_type = x.dataType.toString()
        idx += 1
        field_dataType = ""
        
        data_type match {
            case "IntegerType" | "LongType" | "ShortType" => field_dataType = "Int"
            case "StringType" => field_dataType = "String"
            case "DoubleType" => field_dataType = "Decimal"
            case "DecimalType" => field_dataType = "Decimal"
            case "DateType" => field_dataType = "Date"
            case "FloatType" => field_dataType = "Float" 
            case "BooleanType" => field_dataType = "Boolean"
            case "TimestampType" => field_dataType = "Timestamp"
            case "ListType" => field_dataType = "List" 
        }
//          println(x.name + "  " + x.dataType)
         
        if (columns.contains(field_name)){
          field_name_m = field_name 
          field_dataType_m = field_dataType
          pos = idx - 1
          
          rule_process_fields = rule_process_fields:+((field_name,field_dataType,pos))   
          
          println(field_name_m + " == " + field_name + " " + field_dataType_m + " " + pos)
        }
      }
    }
      
      rule_process_fields.foreach(f => {println("rule_process_fields:" + f + " " + f._1)})
      
//      println("rule_process_fields:" + rule_process_fields)
      
    	var actions = rule_actions.split(",")
    	
    	var num_fields = rule_process_fields.length
    	
    	field_name_m = rule_process_fields(0)._1
    	field_dataType_m = rule_process_fields(0)._2
    	field_pos_m = rule_process_fields(0)._3
    	var pflag = true
    	var cflag = true
    	
    	if (field_name_m == column_name){
    	    if (table_row.getString(field_pos_m) == null || table_row.getString(field_pos_m).trim.isEmpty()){
    	      pflag = false
    	      println("first field test :" + rule_process_fields(0) + "  " + table_row.getString(field_pos_m) + " " + table_row)
    	    }  
    	}
      
      if(pflag){
        for(i <- 1 to num_fields-1){
          field_name_m = rule_process_fields(i)._1
    	    field_dataType_m = rule_process_fields(i)._2
    	    field_pos_m = rule_process_fields(i)._3
    	    
    	    if (table_row.getString(field_pos_m) == null || table_row.getString(field_pos_m).trim.isEmpty()){
    	      cflag = false
    	    }
    	    else{
    	      if (cflag == false)
    	        pflag = false
    	        
    	      cflag = true
    	    }    	      
        }        
      }
      
      else{
        for(i <- 1 to num_fields-1){
          field_name_m = rule_process_fields(i)._1
    	    field_dataType_m = rule_process_fields(i)._2
    	    field_pos_m = rule_process_fields(i)._3
    	    
    	    if (table_row.getString(field_pos_m) == null || table_row.getString(field_pos_m).trim.isEmpty())
    	      pflag = true
    	    else
    	      pflag = false
    	        
        }
          
        println("need to handle records with staring spaces") 
      }
      
      var res = ""
      
      var result_row = List[(String)]()
      
      if ((pflag == true && cflag == false) || (pflag == true && cflag == true) ){
          res = "valid record"
        }else{
          res = "invalid record"
        }
      
        result_row = result_row:+((table_row.toString()))
        result_row = result_row:+((res))
        
        println(result_row)

        println("column priority check:")
    }
    
  sc.stop
  }
}    
  
/*    				
    import sqlContext.implicits._

    val people = sc.textFile("/home/work/input/people.txt")
                   .map(_.split("\t")).map(p => Person(p(0), p(1).trim.toInt)).toDF()
    
    people.registerTempTable("people")

    val teeers = sqlContext.sql("SELECT name, age FROM people WHERE age >= 13 AND age <= 19")

    teenagers.map(t => "Name: " + t(0)).collect().foreach(println)

    teenagers.map(t => "Name: " + t.getAs[String]("name")).collect().foreach(println)

    teenagers.map(_.getValuesMap[Any](List("name", "age"))).collect().foreach(println)
  
// */  
 

use test:

create table test_apps(
app_id varchar(10),
app_name varchar(20),
contact varchar(20)
);

insert into test_apps values("app1","app1","e-mail id");
insert into test_apps values("app2","app2","e-mail id");


create table test_rules(
rule_id int,
rule_desc varchar(50),
rule_type varchar(20),
rule_message varchar(100),
rule_actions varchar(100),
create_timestamp timestamp,
created_user varchar(50)
);

insert into test_rules values(1, "Number data type for column","ERROR","invalid datatype","number,space,null",current_timestamp,"abc");
insert into test_rules values(2, "Data length for column","ERROR","length incorrect","length,space,null",current_timestamp,"abc");
insert into test_rules values(3, "timestamp format YYYY-MM-DD HH24:MI:SS","ERROR","invalid datatype","date,space,null",current_timestamp,"abc");
insert into test_rules values(4, "timestamp for DD/MM/YYYY","ERROR","invalid datatype","date,space,null",current_timestamp,"abc");
insert into test_rules values(5, "column priority check","ERROR","invalid data","space",current_timestamp,"abc");

create table test_master_table(
object_id int,
object_type varchar(10),
schema_name varchar(20),
object_name varchar(50),
column_name varchar(30),
column_datatype varchar(10),
length int,
scale int,
precession int,
app_id varchar(10),
cluster_id varchar(50),
rule_id int,
active_flag int,
operators varchar(50),
file_delim varchar(10),
columns_priority varchar(50)
);
insert into test_master_table values(1, "table","test","test_rules","rule_id","int",0,0,0,"app1","clusterid",1,1,null,null,null);
insert into test_master_table values(2, "table","test","test_rules","rule_desc","varchar",50,0,0,"app1","clusterid",2,1,"<=",null,null);
insert into test_master_table values(3, "table","test","test_rules","rule_type","varchar",20,0,0,"app1","clusterid",2,1,"<=",null,null);
insert into test_master_table values(4, "table","test","test_rules","rule_message","varchar",100,0,0,"app1","clusterid",2,1,"<=",null,null);
insert into test_master_table values(4, "table","test","test_rules","rule_actions","varchar",100,0,0,"app1","clusterid",2,1,"<=",null,null);
insert into test_master_table values(5, "table","test","test_rules","create_timestamp","timestamp",24,0,0,"app1","clusterid",3,1,null,null,null);
insert into test_master_table values(6, "table","test","test_rules","created_user","varchar",50,0,0,"app1","clusterid",2,1,"<=",null,null);
insert into test_master_table values(7, "table","test","test_rules_map","object_id","int",0,0,0,"app1","clusterid",1,1,null,null,null);
insert into test_master_table values(8, "table","test","test_rules_map","rule_id","int",0,0,0,"app1","clusterid",1,1,null,null,null);
insert into test_master_table values(9, "table","test","test_rules_map","active_flag","int",0,0,0,"app1","clusterid",1,1,null,null,null);
insert into test_master_table values(10, "table","test","country_table","country","varchar",20,0,0,"app1","clusterid",5,1,null,null,"country,state,district,city");

create table test_rules_map(
object_id int,
rule_id int,
active_flag int
);
insert into test_rules_map values(1,1,1);
insert into test_rules_map values(2,2,1);
insert into test_rules_map values(3,2,1);
insert into test_rules_map values(4,2,1);
insert into test_rules_map values(5,3,1);
insert into test_rules_map values(6,2,1);
insert into test_rules_map values(7,1,1);
insert into test_rules_map values(8,1,1);
insert into test_rules_map values(9,1,1);
insert into test_rules_map values(10,5,1);

create table country_table(
country varchar(20),
state varchar(20),
district varchar(20),
city varchar(20)
)
insert into country_table values("A"," "," "," ");
insert into country_table values("A","B"," ","");
insert into country_table values("A","B","C"," ");
insert into country_table values("A","B","C","D");
insert into country_table values(" "," "," "," ");
insert into country_table values(" ","B","C","D");
insert into country_table values("A"," ","C","D");
insert into country_table values("A","B"," ","D");
insert into country_table values("A"," "," ","D");
insert into country_table values("A"," ","C",null);


create table test_results(
object_id int,
rule_id int,
run_date timestamp,
result varchar(20),
record_count int,
error_count int,
warning_count int,
comment varchar(100)
);
